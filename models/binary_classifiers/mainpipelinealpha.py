# -*- coding: utf-8 -*-
"""MainPipelineAlpha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12uVchANt3eJ1Nv1NYIzQ77jy_bAh35iD
"""

### Modified May 8th, 2:10PM

use_gdrive = True
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import torch
from torchvision.models.video import r3d_18, R3D_18_Weights
print("we made it here")
# from torchvision.models.video import swin3d_t, Swin3D_T_Weights
print('we did not make it here')
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
import os
import torch.optim as optim
import random
import json
from mainpipeline_helpers import *


data_dir = "datasets"

### assume we have filelistcsv loaded
FileListCSV = pd.read_csv("FileList.csv")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

train_data_dir = data_dir + "/train_batched_downsampled_rebalanced"
val_data_dir = data_dir + "/val_batched_downsampled"
test_data_dir = data_dir + "/test_batched_downsampled"

#  Initialize r3d model with the best available weights
weights1 = R3D_18_Weights.DEFAULT
model1 = r3d_18(weights=weights1)
model1.eval()
#  Another example, swin3d_t model

# model2 = swin3d_t(weights="DEFAULT")
# weights2 = Swin3D_T_Weights.DEFAULT
# model2.eval()

#  Create extended model classes 
# Pretrained r3d and swin3d_t have out_fueature size of (400,1), therefore here we added a linear layer of to reduce size and a sigmoid layer to both models to get desired output form.

model_r3d = r3dmodel(model1)
# model_swin3dt = swin3dmodel(model2)

model = model_r3d

loss_fn = CustomBinaryCrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.0005)
model.to(device)
model.train()

batch_size_fake = 1
batch_size_effective = 20

import random
SEED = 1234
os.environ['PYTHONHASHSEED'] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
# torch.use_deterministic_algorithms(True)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)

    # https://pytorch.org/docs/stable/notes/randomness.html
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

num_epochs = 50

train_loss = []
val_loss = []
train_auc_running = []
val_auc_running = []
train_accuracy_running = []
val_accuracy_running = []

train_running_probabilities = None
val_running_probabilities = None


### CHANGE EVERY TIME YOU RUN!!!!!!!
experiment_name = 'ID1_May8_2023'

best_model_path = data_dir + '/train_batched_normal_models'

best_val_auc = 0

for epoch in range(num_epochs):
  print(f"EPOCH {epoch + 1}")
  print("TRAINING")
  train_epoch_loss, train_epoch_corrects, train_epoch_total, train_epoch_probabilities, train_running_labels, train_running_video_ids, train_running_EF, train_TP, train_TN, train_FP, train_FN = epoch_evaluation(model, train_data_dir, loss_fn, optimizer, batch_size_fake, batch_size_effective, device, training=True)  
  print("VALIDATION")
  val_epoch_loss, val_epoch_corrects, val_epoch_total, val_epoch_probabilities, val_running_labels, val_running_video_ids, val_running_EF,  val_TP, val_TN, val_FP, val_FN = epoch_evaluation(model, val_data_dir, loss_fn, optimizer, batch_size_fake, batch_size_effective, device, training=False)

  train_auc = roc_auc_score(train_running_labels, train_epoch_probabilities)
  val_auc = roc_auc_score(val_running_labels, val_epoch_probabilities)
  train_accuracy = (train_TP + train_TN) / (train_TP + train_TN + train_FP + train_FN)
  val_accuracy = (val_TP + val_TN) / (val_TP + val_TN + val_FP + val_FN)

  train_loss.append(train_epoch_loss)
  val_loss.append(val_epoch_loss)
  train_auc_running.append(train_auc)
  val_auc_running.append(val_auc)
  train_accuracy_running.append(train_accuracy)
  val_accuracy_running.append(val_accuracy)

  if val_auc > best_val_auc:
    best_val_auc = val_auc
    if f'{experiment_name}.pt' in os.listdir(best_model_path):
      os.remove(f'{best_model_path}/{experiment_name}.pt')
    torch.save(model.state_dict(), f'{best_model_path}/{experiment_name}.pt')

    train_running_probabilities = train_epoch_probabilities
    val_running_probabilities = val_epoch_probabilities

  print("SUMMARY: ")
  print(f"EPOCH {epoch + 1} -- Train Loss: {train_epoch_loss} Val Loss: {val_epoch_loss}; Train AUC: {train_auc} Val AUC: {val_auc}; Train Accuracy: {train_accuracy} Val Accuracy: {val_accuracy};")
  print(f"Train [TP, TN, FP, FN] is: {[train_TP, train_TN, train_FP, train_FN]}; Val [TP, TN, FP, FN] is: {[val_TP, val_TN, val_FP, val_FN]}; ")

### CHANGE EVERY TIME YOU RUN!!!!!!!
best_model_path = data_dir + '/train_batched_normal_models'

# from torchvision.models.video import swin3d_t, Swin3D_T_Weights
#  Initialize r3d model with the best available weights
weights1 = R3D_18_Weights.DEFAULT
model1_test = r3d_18(weights=weights1)
model1_test.eval()
#  Another example, swin3d_t model

# model2_test = swin3d_t(weights="DEFAULT")
# weights2 = Swin3D_T_Weights.DEFAULT
# model2_test.eval()

### TESTING!!!
### Make sure to change this line!!!
# best_model = swin3dmodel(model2_test)
best_model = r3dmodel(model1_test)

best_model_parameters = torch.load(f'{best_model_path}/{experiment_name}.pt')
best_model.load_state_dict(best_model_parameters)
best_model.to(device)
test_epoch_loss, test_epoch_corrects, test_epoch_total, test_epoch_probabilities, test_running_labels, test_running_video_ids, test_running_EF, test_TP, test_TN, test_FP, test_FN = epoch_evaluation(best_model, test_data_dir, loss_fn, optimizer, batch_size_fake, batch_size_effective, device, training=False)
print(test_running_EF)
test_auc = roc_auc_score(test_running_labels, test_epoch_probabilities)
test_accuracy = (test_TP + test_TN) / (test_TP + test_TN + test_FP + test_FN)
test_accuracy_check = test_epoch_corrects / test_epoch_total
test_running_probabilities = test_epoch_probabilities

assert (test_accuracy - test_accuracy_check) < 1e-5

print("SUMMARY")
print(f"Test Accuracy is: {test_accuracy}")
print(f"Test AUC is: {test_auc}")
print("[TP, TN, FP, FN] is: ", str([test_TP, test_TN, test_FP, test_FN]))
print("test_epoch_loss is: ", test_epoch_loss)
print(f"Total # of samples is {test_epoch_total}")


fig1, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))
fig2, ax2 = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))
fig3, ax3 = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))


metrics(train_running_probabilities, train_running_labels, ax1, ax2, "Training")
print()
best_val_threshold = metrics(val_running_probabilities, val_running_labels, ax1, ax2, "Validation")
print()
metrics(test_running_probabilities, test_running_labels, ax1, ax2, "Testing", best_val_threshold)
print()
# Create a list of epochs
epochs = list(range(1, len(train_loss) + 1))

# Plot train_loss and val_loss against epochs
ax3.plot(epochs, train_loss, label='Train loss')
ax3.plot(epochs, val_loss, label='Validation loss')

# Add x and y axis labels and a legend
ax3.set_xlabel('Epochs')
ax3.set_ylabel('Loss')
ax3.legend()

if experiment_name not in os.listdir():
  os.mkdir(experiment_name)

fig1.savefig(f'{experiment_name}/final_results_{experiment_name}_ax1')
fig2.savefig(f'{experiment_name}/final_results_{experiment_name}_ax2')
fig3.savefig(f'{experiment_name}/final_results_{experiment_name}_ax3')

numerical_results = {
  "test_running_probabilities": test_running_probabilities,
  "test_running_labels": test_running_labels,
  "test_running_video_ids": test_running_video_ids
}

with open(f'{experiment_name}/numerical_results_{experiment_name}.json', 'w') as file:
  json.dump(numerical_results, file, indent=1)
